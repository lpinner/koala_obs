{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code and ideas modified from agdc/agdc-v2-examples/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "\n",
    "import fiona\n",
    "import pandas\n",
    "import xarray\n",
    "\n",
    "import datacube\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoDataError(Exception):\n",
    "    pass\n",
    "\n",
    "def get_last_oid(csv):\n",
    "    \"\"\"Get last OID from CSV so we can continue where we left off\"\"\"\n",
    "    \n",
    "    df = pandas.read_csv(csv)\n",
    "    return int(df.tail(1).OID)\n",
    "    \n",
    "    \n",
    "def sort_data(data):\n",
    "    \"\"\" Concatenate data from different sensors together \n",
    "        and sort so that observations are sorted by time \n",
    "        rather than by sensor\n",
    "    \"\"\"\n",
    "    \n",
    "    data = xarray.concat(data, dim='time')\n",
    "    time_sorted = data.time.argsort()\n",
    "    data = data.isel(time=time_sorted)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data(query, mask_components, pnbars, pfcs, pqas):\n",
    "    \"\"\"Run a query and return data\"\"\"\n",
    "    \n",
    "    nbars = []\n",
    "    fcs = []\n",
    "    for pnbar, pfc, pqa in zip(pnbars,pfcs,pqas):\n",
    "\n",
    "        #Load the NBAR, FC and corresponding PQ\n",
    "        nbar = dc.load(product=pnbar, measurements=pnbar_measurements, **query)\n",
    "        fc = dc.load(product=pfc, measurements=pfc_measurements, **query)\n",
    "        pq = dc.load(product=pqa, fuse_func=ga_pq_fuser, **query)\n",
    "\n",
    "        #Apply the PQ masks to the data\n",
    "        try:\n",
    "            cloud_free = masking.make_mask(pq, **mask_components)\n",
    "            good_data = cloud_free.pixelquality.loc[query['time'][0]:query['time'][1 ]]\n",
    "            nbar = nbar.where(good_data)\n",
    "            fc = fc.where(good_data)\n",
    "            del cloud_free, good_data\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        nbars.append(nbar)\n",
    "        fcs.append(fc)\n",
    "        del nbar, fc, pq\n",
    "\n",
    "    if not nbars:\n",
    "        raise NoDataError\n",
    "        \n",
    "    #Concatenate data from different sensors together and sort so that observations are sorted by time rather\n",
    "    # than sensor\n",
    "    nbar = sort_data(nbars)\n",
    "    fc = sort_data(fcs)\n",
    "\n",
    "    return nbar, fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Main section\n",
    "This just outputs to CSV, there's no attempt at filtering or analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1995 #sys.argv[1]\n",
    "dc = datacube.Datacube(app='koala-obs')\n",
    "\n",
    "inshp = 'koala_obs_1995_2009.shp'\n",
    "\n",
    "errshp = 'koala_err_%s.shp'%year  #In case there's a dodgy point or two\n",
    "outcsv = 'koala_data_%s.csv'%year #Output csv\n",
    "\n",
    "sensors = [\n",
    "    'ls7',\n",
    "    'ls5'\n",
    "] \n",
    "\n",
    "pnbar_measurements=['red', 'nir']\n",
    "pfc_measurements=['BS']\n",
    "\n",
    "query = {\n",
    "    'output_crs':'EPSG:4326',\n",
    "    'resolution':(-0.00025, 0.00025),\n",
    "    'group_by':'solar_day'\n",
    "\n",
    "}\n",
    "\n",
    "#PQA Mask\n",
    "mask_components = {\n",
    "    'cloud_acca':'no_cloud',\n",
    "    'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "    'cloud_fmask' :'no_cloud',\n",
    "    'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "    'contiguous':True,\n",
    "    'red_saturated' : False,\n",
    "    'nir_saturated' : False,\n",
    "}\n",
    "\n",
    "pnbars = ['{}_nbar_albers'.format(s) for s in sensors]\n",
    "pfcs = ['{}_fc_albers'.format(s)   for s in sensors]\n",
    "pqas = ['{}_pq_albers'.format(s)   for s in sensors]\n",
    "\n",
    "# Get last OBJECTID so we can pick up where we left off after a crash or VDI session getting killed\n",
    "try:\n",
    "    last_oid = get_last_oid(outcsv)\n",
    "except (FileNotFoundError,TypeError):  # file doesn't exist, or exists but has no data\n",
    "    last_oid = -1\n",
    "    with open(outcsv, 'w') as out:\n",
    "        out.write('time,latitude,longitude,NDVI,SAVI,OID' + '\\n')\n",
    "\n",
    "with fiona.open(inshp, 'r') as source, open(outcsv, 'a') as out:\n",
    "\n",
    "    recs = filter(lambda r:  \n",
    "                  int(r['properties']['DYEAR']) == int(year) and int(r['properties']['OBJECTID']) > last_oid, \n",
    "                  source)\n",
    "\n",
    "    driver = source.driver\n",
    "    crs = source.crs\n",
    "    schema = source.schema.copy()\n",
    "    schema['properties']['ORIGID']=schema['properties']['OBJECTID']\n",
    "\n",
    "    with fiona.open(errshp, 'a', \n",
    "                    driver=driver,\n",
    "                    crs=crs,\n",
    "                    schema=schema) as err:\n",
    "\n",
    "\n",
    "        for i,rec in enumerate(recs):\n",
    "\n",
    "            x,y = rec['geometry']['coordinates']\n",
    "            oid = rec['properties']['OBJECTID']\n",
    "            rec['properties']['ORIGID'] = oid\n",
    "\n",
    "            print('%s\\t%s\\t%s'%(year,i,oid))\n",
    "\n",
    "            query['time'] = ('%s-01-01'%year, '%s-12-31'%year)\n",
    "            query['lon'] = (x-0.00025,x+0.00025)\n",
    "            query['lat'] = (y-0.00025,y+0.00025)\n",
    "\n",
    "            try:\n",
    "                nbar, fc = get_data(query, mask_components, pnbars, pfcs, pqas)\n",
    "                px,py=(int(xy) for xy in ~nbar.affine * (x,y))\n",
    "\n",
    "                nbar = nbar.isel(longitude=px,latitude=px).dropna('time', how = 'any')\n",
    "                fc = fc.isel(longitude=px,latitude=px).dropna('time', how = 'any')\n",
    "\n",
    "                red, nir, lfac = nbar.red/10000, nbar.nir/10000, fc.BS/100\n",
    "                ndvi = ((nir-red)/(nir+red))\n",
    "                savi = ((nir-red)/(nir+red+lfac))*(1+lfac)\n",
    "\n",
    "                ndvids=ndvi.to_dataset(name='NDVI')\n",
    "                savids=savi.to_dataset(name='SAVI')\n",
    "                ds = xarray.merge([ndvids,savids])\n",
    "                ds['OID'] = oid\n",
    "\n",
    "                df=ds.to_dataframe()\n",
    "                df.to_csv(out, index=True, header=False)\n",
    "\n",
    "            except (NoDataError, ValueError):\n",
    "                print('No data for rec {} ({},{})'.format(oid,x,y))\n",
    "                err.write(rec)\n",
    "                continue\n",
    "            except (Exception):\n",
    "                import traceback\n",
    "                print('Unhandled exception for rec {} ({})'.format(oid,year))\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fc.BS.plot(linestyle= '--', c= 'b', marker = '8', mec = 'b', mfc ='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ndvi.plot(linestyle= '--', c= 'b', marker = '8', mec = 'b', mfc ='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#savi.plot(linestyle= '--', c= 'b', marker = '8', mec = 'b', mfc ='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
